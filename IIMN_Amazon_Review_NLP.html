<!DOCTYPE HTML>
<html lang="en">
	<head>
    	<title>Analyzing Amazon Reviews, Textual Metrics, and User’s Perceived Helpfulness</title>
    	<meta charset="utf-8" />
    	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    	<link rel="stylesheet" href="assets/css/main.css" />
    	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
    	<style>
            /* Add custom styles for the border */
            .container {
                border: 5px solid #333; /* Dark border color */
                padding: 25px;  /* Add some padding inside the border */
                margin: 75px;   /* Add space between the border and page edges */
                border-radius: 50px; /* Rounded corners */
                background-color: #fff; /* White background for the container */
                color: #555; /* Dark text color for better readability */
            }

            /* Set background color for the whole page and text color */
            body {
                background-color: #f4f4f4; /* Light gray background for the page */
                color: #333; /* Set a darker text color globally */
                font-family: Arial, sans-serif; /* Set a clean and readable font */
            }

            /* Set dark color for all headings */
            h1, h2, h3 {
                color: #222; /* Darker color for headings */
            }

            /* Add orange line under each section heading */
            h2 {
                display: inline-block; /* Make the line only as wide as the heading */
                border-bottom: 3px solid #f56a6a; /* Orange color for the line */
                padding-bottom: 5px; /* Add some space between the text and the line */
                margin-bottom: 20px; /* Space below the line */
            }

            /* Adjust paragraph and other text content */
            p {
                color: #333; /* Dark text for paragraphs */
                line-height: 1.6; /* Add spacing between lines for easier reading */
            }

            /* Style for the buttons */
            .button-container {
                text-align: center; /* Center the buttons */
                margin-top: 20px; /* Space above buttons */
                margin-bottom: 20px;
            }
            .button-container .button {
                display: initial; /* Side-by-side buttons */
                margin: 0 50px; /* Space between buttons */
                padding: 10px 20px; /* Smaller padding for smaller buttons */
                font-size: 14px; /* Smaller font size */
            }

            /* Visualization Styles */
            .graph-container {
                width: 100%;
                display: block; /* Ensure rows stack vertically */
                padding: 20px 0; /* Add padding for spacing */
            }
            .graph-row {
                display: flex;
                justify-content: space-evenly; /* Even spacing between boxes */
                flex-wrap: nowrap; /* Keep items side by side */
                margin-bottom: 30px; /* Space between rows */
                width: 100%;
                align-items: stretch; /* Ensure boxes stretch to match the tallest in the row */
            }
            .graph-box {
                width: 48%; /* Two boxes per row with small gap */
                display: flex; /* Flexbox for vertical and horizontal centering */
                flex-direction: column; /* Stack image and caption vertically */
                justify-content: center; /* Center content vertically within the box */
                align-items: center; /* Center content horizontally within the box */
                background: #fff; /* White background for the box */
                padding: 15px; /* Padding inside the box */
                border-radius: 8px; /* Rounded corners */
                box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.2); /* Shadow around the box */
                text-align: center; /* Center-align content */
                position: relative; /* Ensure caption stays within box */
                min-height: 300px; /* Minimum height to ensure vertical centering */
            }
            .graph {
                max-width: 100%; /* Responsive image */
                height: auto; /* Maintain aspect ratio */
                border-radius: 5px; /* Rounded corners */
                border: 2px solid #ddd; /* Light gray border */
                margin-bottom: 5px; /* Small space between image and caption */
                object-fit: contain; /* Ensure image fits without distortion */
            }
            .graph-caption {
                font-size: 14px; /* Smaller font for captions */
                color: #333; /* Match paragraph text color */
                display: block; /* Simplified display for text */
                padding: 0 10px; /* Add padding to prevent text from touching edges */
                overflow-wrap: break-word; /* Allow text to wrap within the box */
                word-break: break-word; /* Ensure long words break */
                margin-top: 0; /* Remove any default top margin */
            }

            /* Style for Table Box */
            .table-box {
                background: #fff; /* White background */
                padding: 15px; /* Padding inside the box */
                border-radius: 8px; /* Rounded corners */
                box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.2); /* Shadow for consistency */
                margin-bottom: 20px; /* Space between table and next content */
                text-align: center; /* Center-align content */
                width: 100%; /* Full width within container */
                max-width: 1000px; /* Limit maximum width for readability */
                margin: 0 auto; /* Center the box horizontally on the page */
                overflow-x: auto; /* Enable horizontal scrolling if table is too wide */
            }
            .table-box table {
                width: 100%; /* Full width of the box */
                border-collapse: collapse; /* Collapse borders for clean look */
                font-size: 14px; /* Match font size of captions and text */
                color: #333; /* Match paragraph text color */
            }
            .table-box caption {
                font-size: 14px; /* Smaller font for caption */
                color: #666; /* Slightly lighter for distinction */
                padding-bottom: 10px; /* Space below caption */
                caption-side: top; /* Place caption above table */
            }
            .table-box th, .table-box td {
                border: 1px solid #ddd; /* Light gray border */
                padding: 10px; /* Padding inside cells */
                text-align: center; /* Center-align text */
            }
            .table-box th {
                background-color: #f56a6a; /* Orange background for headers, matching theme */
                color: #fff; /* White text for contrast */
                font-weight: bold; /* Bold headers */
            }
            .table-box tr:hover {
                background-color: #f9f9f9; /* Light gray on hover for readability */
            }

            /* Back Button Styles */
            .back-button {
                position: absolute;
                top: 20px;
                left: 30px;
                font-size: 30px;
                color: #f56a6a;
                text-decoration: none;
                z-index: 10;
                transition: color 0.3s ease;
            }
            .back-button:hover {
                color: #d45252;
            }
            header {
                position: relative;
                padding-top: 5px; /* Space for the back button */
            }
        </style>
    </head>

	<body class="is-preload">
            <!-- Header Section -->
            <header>
                <a href="index.html#all-projects" class="back-button"><i class="fas fa-arrow-left"></i></a>
            </header>
            <div class="container">
                <h1 style="text-align: center;">Analyzing Amazon Reviews, Textual Metrics, and User’s Perceived Helpfulness</h1>
                <p style="text-align: center; font-weight: 150; text-transform: uppercase;" class="project-description">This study analyzes factors influencing review helpfulness using the Amazon Review/Product Dataset, focusing on Cell Phones and Accessories and Video Games categories with advanced text analysis and modeling techniques.</p>
                <div class="button-container">
                    <a href="https://github.com/suryam1504/IIMN-Analyzing-Amazon-Reviews-Textual-Metrics-and-Users-Perceived-Helpfulness" target="_blank" class="button">GitHub</a>
                    <a href="IIMN_Amazon_Review_NLP_Report.html" target="_blank" class="button">Detailed Report</a>
                </div>
            

            <!-- Background Section -->
            <section id="background">
                <h2>Background</h2>
                <p>Online reviews significantly influence consumer purchasing decisions by providing insights into product quality. 
                    The <a href="https://nijianmo.github.io/amazon/index.html" target="_blank">Amazon Review/Product Dataset</a>, provided by Julian McAuley 
                    and Jianmo Ni from UCSD, contains 233.1 million reviews from May 1996 to October 2018. This project examines the "Cell Phones and 
                    Accessories" and "Video Games" categories to identify how features like writing style and media elements correlate with helpfulness votes, using tools like 
                    LIWC and LDA.</p>
            </section>

            <!-- Research Question Section -->
            <section id="research-question">
                <h2>Research Question</h2>
                <p>How do review writing style, length, readability, balance, breadth, verified purchase status, number of entities, and presence of images affect the perceived 
                    helpfulness (votes) of Amazon reviews in the Cell Phones and Accessories and Video Games categories?</p>
            </section>

            <!-- Hypothesis Section -->
            <section id="hypothesis">
                <h2>Hypothesis</h2>
                <p>“Features such as analytical writing style, optimal review length, readability, balanced sentiment, topic breadth, verified purchase status, number of entities, and presence of images will exhibit varying correlations (positive, negative, or curvilinear) with helpfulness votes, with specific thresholds optimizing impact.”</p>
                <p>This is informed by research on content richness and authority cues in online reviews.</p>
            </section>

            <!-- Dataset Section -->
            <section id="dataset">
                <h2>Dataset</h2>
                <p>The <a href="https://nijianmo.github.io/amazon/index.html" target="_blank">Amazon Review/Product Dataset</a> from UCSD includes 233.1 million reviews from May 1996 to October 2018. This project focuses on 'Cell Phones and Accessories' (1,128,437 review rows, 590,071 metadata rows) and 'Video Games' (231,780 review rows, 84,819 metadata rows), with review data (e.g., text, votes) and metadata (e.g., price, brand). These are raw data figures before cleaning.</p>
            </section>

            <!-- Data Pre-processing and Cleaning Section -->
            <section id="data-preprocessing">
                <h2>Data Cleaning, Pre-processing, and EDA</h2>
                <p>JSON files were converted to Python dataframes. Duplicates were removed to avoid data contamination. Review and metadata were merged using ASIN numbers. 
                    Unimportant columns and rows with NaN or numeric values in 'reviewText' were dropped. NaN votes were replaced with zero. Post-cleaning, Cell Phones and 
                    Accessories had 1,041,169 rows and 18 columns, while Video Games had 28,133 rows and 28 columns.<br>
                    EDA processed 'reviewText' by extracting sentence count, removing stopwords and numbers, converting to lowercase, applying lemmatization, and calculating word 
                    and unique word counts. The 'rank' column was mined to extract product rank and category/sub-category names for enhanced feature analysis.</p>
            </section>

            <!-- Linguistic Inquiry and Word Count (LIWC) Section -->
            <section id="liwc">
                <h2><a href="https://www.liwc.app/" target="_blank">Linguistic Inquiry and Word Count (LIWC) - 22 <i class="fas fa-external-link-alt"></i></a></h2>
                <p>LIWC-22 is a text analysis software that gives more
                    profound insights into the words in the corpus. When applied on the dataset, it gives 118
                    features for any review, such as Authentic, Emotional Tone, Past Focus, etc. In order to
                    calculate these statistics, each dictionary word is measured as a percentage of total words per
                    text (Cronbach’s α) or, alternatively, in a binary “present versus absent” manner (Kuder–
                    Richardson Formula 20; Kuder & Richardson, 1937).</p>
            </section>

            <!-- Topic Modeling using LDA Section -->
            <section id="lda">
                <h2>Topic Modeling using LDA</h2>
                <li><strong>Introduction:</strong> LDA is an unsupervised method to extract topics from documents using word cluster patterns, ideal for large datasets like Amazon reviews.</li>
                <li><strong>Latent Dirichlet Allocation (LDA):</strong> A Bayesian model sampling over a probability simplex, assigning words to k=7 topics, providing word-topic probabilities and document representations.</li>
                <li><strong>Choosing Optimal Number of Topics:</strong> With consistent coherence (6-20), k=7 was selected using pyLDAvis for large, non-overlapping bubbles, indicating distinct topics.</li>
                <li><strong>Calculating Dominant Topic and Total Important Topics:</strong> Dominant Topic is the highest probability topic; Total Important Topics counts topics above a 0.05 threshold, aiding vote correlation analysis.<br><br></li>
            </section>

            <!-- Feature Extraction Section -->
            <section id="feature-extraction">
                <h2>Feature Extraction</h2>
                <p>The following features were extracted from the Amazon Review/Product Dataset to analyze their impact on perceived helpfulness (votes). Extraction methods leveraged text processing, LIWC, NER, and topic modeling techniques, as detailed below:</p>
                <ol>
                    <li><strong>Review Writing Style (Analytic):</strong> This feature was extracted using the LIWC-22 "Analytic" summary variable, which quantifies logical and formal thinking in text. Each review’s text was processed by LIWC to produce a score (0-100), where higher scores indicate structured, analytical writing (e.g., using articles and prepositions), and lower scores reflect a narrative style.</li>
                    <li><strong>Review Length (WPS):</strong> Review length was calculated as Words Per Sentence (WPS) by dividing the total word count by the sentence count in each review’s "reviewText." Both metrics were derived using LIWC’s built-in word and sentence segmentation, providing a measure of review verbosity.</li>
                    <li><strong>Review Readability (FRE):</strong> Readability was assessed with the Flesch Reading Ease (FRE) index, computed as FRE = 206.835 - (1.015 * Avg. words per sentence) - (84.6 * Avg. syllables per word). Average words per sentence and syllables per word were extracted from "reviewText" using text processing tools, yielding a score where higher values indicate easier comprehension.</li>
                    <li><strong>Review Balance:</strong> This was measured as the ratio of LIWC’s positive tone (tone_pos) to negative tone (tone_neg) variables. Both tones were extracted as percentages of words reflecting positive or negative sentiment in each review, providing a balance metric to assess sentiment neutrality or bias.</li>
                    <li><strong>Review Breadth:</strong> Breadth was determined using Latent Dirichlet Allocation (LDA) topic modeling with k=7 topics. The "reviewText" was processed to assign topic probabilities, and the count of topics with probabilities above a 0.05 threshold was calculated as Total Important Topics, reflecting the diversity of subjects covered.</li>
                    <li><strong>Verified Purchase:</strong> Extracted directly from the dataset’s "verified" field, this binary feature was coded as a dummy variable (1 = TRUE for verified purchase, 0 = FALSE), indicating whether the reviewer purchased the product on Amazon.</li>
                    <li><strong>Number of Entities:</strong> Named Entity Recognition (NER) via the spaCy library was applied to "reviewText" to identify and count entities (e.g., product names, brands, locations). The total entity count per review was recorded as a measure of informational detail.</li>
                    <li><strong>Review with Image:</strong> This feature was derived from the "image" field in the dataset, coded as a dummy variable (1 = image URL present, 0 = absent), indicating whether a review included user-uploaded images alongside text.</li>
                </ol>
            </section>

            <!-- Data Visualizations Section -->
            <section id="visualizations">
                <h2>Graphs and Plots</h2>
                <p>Below are visualizations illustrating key insights from the analysis of review helpfulness.</p>
                <div class="graph-container">
                    <!-- First Row: Word Clouds -->
                    <div class="graph-row">
                        <div class="graph-box">
                            <img src="images/IIMN_model.png" alt="Perceived Helpfulness Model" class="graph">
                            <p class="graph-caption">Figure 1: Perceived Helpfulness Model</p>
                        </div>
                        <div class="graph-box">
                            <img src="images/IIMN_WordCloud.png" alt="Word Cloud - Cell Phones and Accessories Reviews" class="graph">
                            <p class="graph-caption">Figure 2: Word Cloud for Cell Phones and Accessories Reviews shows terms like 'phone,' 'review,' 'screen,' 'nokia, 'android,' etc.</p>
                        </div>
                    </div>
                    <!-- Second Row: Correlations and Topic Distribution -->
                    <div class="graph-row">
                        <div class="graph-box">
                            <img src="images/IIMN_TopicModel_df.png" alt="The promiment words which represent each of the 7 topics" class="graph">
                            <p class="graph-caption">Figure 3: The promiment words which represent each of the 7 topics</p>
                        </div>
                        <div class="graph-box">
                            <img src="images/IIMN_TopicModel_df2.png" alt="Probability Distribution among the 7 topics and calculation of Dominant and Total Important Topics" class="graph">
                            <p class="graph-caption">Figure 4: Probability Distribution among the 7 topics and calculation of Dominant and Total Important Topics</p>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Model Section -->
            <section id="model">
                <h2>Model and Findings</h2>
                <p>Features affecting perceived helpfulness (votes) include:</p>
                <ol>
                    <li><strong>Review Writing Style (Analytic):</strong> LIWC’s Analytic score (0-100) measures logical thinking; higher scores positively correlate with votes, enhancing trust and clarity.</li>
                    <li><strong>Review Length (WPS):</strong> Words per sentence shows a curvilinear relationship; moderate lengths optimize helpfulness, while extremes reduce it.</li>
                    <li><strong>Review Readability (FRE):</strong> FRE exhibits a curvilinear relationship; moderate readability balances simplicity and depth, maximizing votes.</li>
                    <li><strong>Review Balance:</strong> Ratio of positive to negative tone is curvilinear; balanced reviews (acknowledging pros and cons) are deemed most helpful.</li>
                    <li><strong>Review Breadth:</strong> Topic count via LDA is curvilinear; moderate topics provide depth without confusion, boosting helpfulness.</li>
                    <li><strong>Verified Purchase:</strong> Dummy variable (1 = TRUE, 0 = FALSE) positively correlates with votes, indicating higher credibility.</li>
                    <li><strong>Number of Entities:</strong> NER count positively correlates with votes; detailed entity mentions enhance informativeness.</li>
                    <li><strong>Review with Image:</strong> Dummy variable (1 = with image, 0 = without) highly positively correlates with votes, adding visual credibility.</li>
                </ol>
            </section>

            <!-- Conclusion Section -->
            <section id="conclusion">
                <h2>Conclusion</h2>
                <p>This study reveals that review helpfulness is influenced by multiple factors. Analytical writing style (positive correlation) enhances clarity and trust, with higher LIWC Analytic scores linked to more votes. Review length (curvilinear) peaks at moderate lengths, avoiding extremes of brevity or verbosity. Readability (curvilinear), measured by FRE, optimizes at a balance between simplicity and depth. Review balance (curvilinear) favors nuanced perspectives over biased tones. Review breadth (curvilinear), via LDA with k=7, benefits from moderate topic coverage. Verified purchase status (positive) and number of entities (positive) boost credibility and informativeness. Reviews with images (highly positive) add visual proof, significantly increasing votes, though relevance is key. These findings suggest that content richness, authority, and multimedia cues are critical drivers of perceived helpfulness, with optimal thresholds enhancing model predictions for vote counts.</p>
            </section>

            <!-- References Section -->
            <section id="references">
                <h2>References</h2>
                <p>
                    1. Xu, K., & Zhang, C. (2018). Content richness in social media.<br>
                    2. Pennebaker, J. W., et al. (2015). Writing style and engagement.<br>
                    3. Choi, W., & Stvilia, B. (2015). Writing styles and impressions.<br>
                    4. Zheng, L., et al. (2021). Information seeking in risky situations.<br>
                    5. Liu, F., et al. (2014). Rumor retransmission in disasters.<br>
                    6. Allport, G. W., & Postman, L. (1947). Psychology of rumor.<br>
                    7. Analytics Vidhya. (2022). Text cleaning methods in NLP.<br>
                    8. Analytics Vidhya. (2021). Topic modeling in NLP.<br>
                    9. DZone. (n.d.). Topic modeling techniques and AI models.<br>
                    10. Stack Overflow. (n.d.). Determining number of topics for LDA.<br>
                    11. Neptune.ai. (n.d.). pyLDAvis topic modeling tool.<br>
                    12. Ni, J., Li, J., & McAuley, J. (2019). Justifying recommendations using distantly-labeled reviews. EMNLP-IJCNLP.
                </p>
            </section>

            <!-- Citation Section -->
            <!--<section id="citation">
                <h2>Citation</h2>
                <p>Please cite the following if you use the data in any way: <br>
                    <i>Ni, J., Li, J., & McAuley, J. (2019, November). Justifying recommendations using distantly-labeled
                    reviews and fine-grained aspects. In Proceedings of the 2019 conference on empirical methods in
                    natural language processing and the 9th international joint conference on natural language
                    processing (EMNLP-IJCNLP) (pp. 188-197).</i></p>
            </section>-->

            <!-- Footer -->
            <footer>
                <p>Created by Suryam Gupta. © 2025</p>
            </footer>
        </div>
	</body>
</html>